{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(model, input_size, batch_size=-1, device=torch.device('cuda:0'), dtypes=None):\n",
    "    result, params_info = summary_string(\n",
    "        model, input_size, batch_size, device, dtypes)\n",
    "    print(result)\n",
    "\n",
    "    return params_info\n",
    "\n",
    "\n",
    "def summary_string(model, input_size, batch_size=-1, device=torch.device('cuda:0'), dtypes=None):\n",
    "    if dtypes == None:\n",
    "        dtypes = [torch.FloatTensor]*len(input_size)\n",
    "\n",
    "    summary_str = ''\n",
    "\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # multiple inputs to the network\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    # batch_size of 2 for batchnorm\n",
    "    x = [torch.rand(2, *in_size).type(dtype).to(device=device)\n",
    "         for in_size, dtype in zip(input_size, dtypes)]\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    # make a forward pass\n",
    "    # print(x.shape)\n",
    "    model(*x)\n",
    "\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    summary_str += \"----------------------------------------------------------------\" + \"\\n\"\n",
    "    line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "        \"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "    summary_str += line_new + \"\\n\"\n",
    "    summary_str += \"================================================================\" + \"\\n\"\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        # input_shape, output_shape, trainable, nb_params\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "\n",
    "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"] == True:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "        summary_str += line_new + \"\\n\"\n",
    "\n",
    "    # assume 4 bytes/number (float on cuda).\n",
    "    total_input_size = abs(np.prod(sum(input_size, ()))\n",
    "                           * batch_size * 4. / (1024 ** 2.))\n",
    "    total_output_size = abs(2. * total_output * 4. /\n",
    "                            (1024 ** 2.))  # x2 for gradients\n",
    "    total_params_size = abs(total_params * 4. / (1024 ** 2.))\n",
    "    total_size = total_params_size + total_output_size + total_input_size\n",
    "\n",
    "    summary_str += \"================================================================\" + \"\\n\"\n",
    "    summary_str += \"Total params: {0:,}\".format(total_params) + \"\\n\"\n",
    "    summary_str += \"Trainable params: {0:,}\".format(trainable_params) + \"\\n\"\n",
    "    summary_str += \"Non-trainable params: {0:,}\".format(total_params -\n",
    "                                                        trainable_params) + \"\\n\"\n",
    "    summary_str += \"----------------------------------------------------------------\" + \"\\n\"\n",
    "    summary_str += \"Input size (MB): %0.2f\" % total_input_size + \"\\n\"\n",
    "    summary_str += \"Forward/backward pass size (MB): %0.2f\" % total_output_size + \"\\n\"\n",
    "    summary_str += \"Params size (MB): %0.2f\" % total_params_size + \"\\n\"\n",
    "    summary_str += \"Estimated Total Size (MB): %0.2f\" % total_size + \"\\n\"\n",
    "    summary_str += \"----------------------------------------------------------------\" + \"\\n\"\n",
    "    # return summary\n",
    "    return summary_str, (total_params, trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dTF(nn.Conv2d):\n",
    "    \"\"\"Conv2d with padding behavior from Tensorflow\n",
    "\n",
    "    adapted from\n",
    "    https://github.com/mlperf/inference/blob/16a5661eea8f0545e04c86029362e22113c2ec09/others/edge/object_detection/ssd_mobilenet/pytorch/utils.py#L40\n",
    "    as referenced in this issue:\n",
    "    https://github.com/pytorch/pytorch/issues/3867#issuecomment-507025011\n",
    "\n",
    "    used to maintain behavior of original implementation of TweetyNet that used Tensorflow 1.0 low-level API\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Conv2dTF, self).__init__(*args, **kwargs)\n",
    "        self.padding = kwargs.get(\"padding\", \"SAME\")\n",
    "\n",
    "    def _compute_padding(self, input, dim):\n",
    "        input_size = input.size(dim + 2)\n",
    "        filter_size = self.weight.size(dim + 2)\n",
    "        effective_filter_size = (filter_size - 1) * self.dilation[dim] + 1\n",
    "        out_size = (input_size + self.stride[dim] - 1) // self.stride[dim]\n",
    "        total_padding = max(\n",
    "            0, (out_size - 1) * self.stride[dim] + effective_filter_size - input_size\n",
    "        )\n",
    "        additional_padding = int(total_padding % 2 != 0)\n",
    "\n",
    "        return additional_padding, total_padding\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.padding == \"VALID\":\n",
    "            return F.conv2d(\n",
    "                input,\n",
    "                self.weight,\n",
    "                self.bias,\n",
    "                self.stride,\n",
    "                padding=0,\n",
    "                dilation=self.dilation,\n",
    "                groups=self.groups,\n",
    "            )\n",
    "        rows_odd, padding_rows = self._compute_padding(input, dim=0)\n",
    "        cols_odd, padding_cols = self._compute_padding(input, dim=1)\n",
    "        if rows_odd or cols_odd:\n",
    "            input = F.pad(input, [0, cols_odd, 0, rows_odd])\n",
    "\n",
    "        return F.conv2d(\n",
    "            input,\n",
    "            self.weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            padding=(padding_rows // 2, padding_cols // 2),\n",
    "            dilation=self.dilation,\n",
    "            groups=self.groups,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(1, 257, 88)\n",
    "conv1_filters=32\n",
    "conv1_kernel_size=(5, 5)\n",
    "conv2_filters=64\n",
    "conv2_kernel_size=(5, 5)\n",
    "pool1_size=(8, 1)\n",
    "pool1_stride=(8, 1)\n",
    "pool2_size=(8, 1)\n",
    "pool2_stride=(8, 1)\n",
    "\n",
    "\n",
    "cnn = nn.Sequential(\n",
    "            Conv2dTF(in_channels=input_shape[0],\n",
    "                     out_channels=conv1_filters,\n",
    "                     kernel_size=conv1_kernel_size,\n",
    "                     padding='same'\n",
    "                     ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=pool1_size,\n",
    "                         stride=pool1_stride),\n",
    "            Conv2dTF(in_channels=conv1_filters,\n",
    "                      out_channels=conv2_filters,\n",
    "                      kernel_size=conv2_kernel_size,\n",
    "                     padding = 'same'\n",
    "                     ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=pool2_size,\n",
    "                         stride=pool2_stride),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_shape = tuple((1,) + input_shape)\n",
    "tmp = torch.rand(batch_shape)\n",
    "tmp_out = cnn(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "          Conv2dTF-1          [-1, 32, 257, 88]             832\n",
      "              ReLU-2          [-1, 32, 257, 88]               0\n",
      "         MaxPool2d-3           [-1, 32, 32, 88]               0\n",
      "          Conv2dTF-4           [-1, 64, 32, 88]          51,264\n",
      "              ReLU-5           [-1, 64, 32, 88]               0\n",
      "         MaxPool2d-6            [-1, 64, 4, 88]               0\n",
      "================================================================\n",
      "Total params: 52,096\n",
      "Trainable params: 52,096\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 14.65\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 14.94\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(52096), tensor(52096))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=cnn, input_size=input_shape, batch_size=-1, device=torch.device('cpu'), dtypes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 8, 88])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = tmp_out.shape[1] * tmp_out.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tmp_out.view(1, n_features, -1).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 88, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(\n",
    "    input_size=n_features,\n",
    "    hidden_size=n_features,\n",
    "    num_layers=1,\n",
    "    dropout=0,\n",
    "    bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_out, (hidden, cell_state) = rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 88, 1024])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(2 * n_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fc(rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 88, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
